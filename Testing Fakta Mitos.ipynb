{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c53691",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitos = [\"Menggunakan kacamata atau lensa kontak terlalu sering dapat membuat mata malas. Faktanya, kacamata atau lensa kontak membantu memperbaiki gangguan penglihatan dan mencegah masalah lebih lanjut.\",\n",
    "\"Duduk terlalu dekat dengan layar komputer dapat merusak penglihatan. Meskipun dapat menyebabkan ketegangan mata, posisi duduk dekat dengan layar tidak merusak mata secara permanen.\",\n",
    "\"Menggunakan wortel secara berlebihan akan meningkatkan penglihatan dengan cepat. Sementara wortel mengandung vitamin A yang baik untuk mata, konsumsi berlebihan tidak meningkatkan penglihatan.\",\n",
    "\"Bersepeda dapat menyebabkan kebutaan. Ini adalah mitos; bersepeda sebenarnya adalah kegiatan yang baik untuk kesehatan secara keseluruhan, termasuk kesehatan mata.\",\n",
    "\"Mata hanya perlu diperiksa jika ada masalah penglihatan. Tes mata secara berkala penting untuk mendeteksi masalah mata sejak dini, bahkan jika Anda tidak mengalami gejala.\",\n",
    "\"Menggunakan tetes mata secara berlebihan dapat menyebabkan ketergantungan. Menggunakan tetes mata sesuai petunjuk dokter tidak menyebabkan ketergantungan.\",\n",
    "\"Membaca dalam cahaya redup akan merusak mata. Ini hanya menyebabkan ketegangan mata sementara, tetapi tidak merusak mata secara permanen.\",\n",
    "\"Menggosok mata saat gatal dapat menyebabkan penyebaran infeksi. Menggosok mata yang gatal dapat menyebabkan infeksi jika tangan Anda kotor, tetapi bukan karena tindakan menggosoknya itu sendiri.\",\n",
    "\"Mata harus beristirahat sebentar setelah melihat layar komputer. Meskipun istirahat adalah ide yang baik, tidak ada bukti bahwa istirahat sebentar setelah melihat layar akan memperbaiki masalah penglihatan.\",\n",
    "\"Terlalu banyak membaca dalam cahaya rendah atau membaca dengan buruk dapat merusak mata. Meskipun membaca dalam kondisi pencahayaan yang buruk dapat menyebabkan ketegangan mata sementara, itu tidak akan merusak mata secara permanen.\",\n",
    "]\n",
    "\n",
    "fakta = [\"Paparan sinar ultraviolet (UV) dari sinar matahari dapat menyebabkan kerusakan mata. Penggunaan kacamata hitam yang memiliki perlindungan UV dapat membantu mengurangi risiko ini.\",\n",
    "\"Diabetes dapat mempengaruhi kesehatan mata. Kondisi ini dapat menyebabkan retinopati diabetik, yaitu kerusakan pembuluh darah pada retina yang dapat mengganggu penglihatan.\",\n",
    "\"Perubahan penglihatan terjadi secara alami seiring bertambahnya usia. Ini termasuk presbyopia, yang menyebabkan kesulitan melihat objek dekat pada usia lanjut.\",\n",
    "\"Merokok dapat meningkatkan risiko terjadinya katarak dan degenerasi makula, dua kondisi mata yang dapat menyebabkan kehilangan penglihatan.\",\n",
    "\"Konsumsi makanan bergizi, seperti makanan kaya vitamin A, C, E, dan mineral seperti seng, dapat membantu menjaga kesehatan mata.\",\n",
    "\"Mata kering adalah kondisi yang umum terjadi, terutama pada mereka yang banyak bekerja di depan layar komputer. Istirahat reguler dan tetes mata bisa membantu mengurangi ketidaknyamanan mata kering.\",\n",
    "\"Penggunaan komputer dan perangkat elektronik lainnya dalam jangka waktu yang lama dapat menyebabkan Computer Vision Syndrome (CVS), menyebabkan gejala seperti mata kering, sakit kepala, dan ketegangan leher.\",\n",
    "\"Bentuk fisik mata setiap orang berbeda. Ada tiga tipe mata utama: mata datar, mata cekung, dan mata normal. Ini dapat mempengaruhi pemilihan kacamata atau lensa kontak yang tepat.\",\n",
    "\"Kacamata hitam yang baik melindungi mata dari sinar UV dan meminimalkan paparan sinar biru dari layar komputer atau perangkat elektronik lainnya.\",\n",
    "\"Deteksi dini adalah kunci untuk mencegah banyak masalah mata yang serius. Berkunjung ke dokter mata secara berkala dapat membantu mendeteksi dan mengatasi masalah mata sejak dini.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8433488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4960b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fcc4646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Menggunakan kacamata atau lensa kontak terlalu sering dapat membuat mata malas. Faktanya, kacamata atau lensa kontak membantu memperbaiki gangguan penglihatan dan mencegah masalah lebih lanjut.', 0)\n",
      "('Paparan sinar ultraviolet (UV) dari sinar matahari dapat menyebabkan kerusakan mata. Penggunaan kacamata hitam yang memiliki perlindungan UV dapat membantu mengurangi risiko ini.', 1)\n"
     ]
    }
   ],
   "source": [
    "# Kasih target setiap kalimat, 0 = mitos, 1 = fakta\n",
    "labelledMitos = [(kalimat, 0) for kalimat in mitos]\n",
    "labelledFakta = [(kalimat, 1) for kalimat in fakta]\n",
    "print(labelledMitos[0])\n",
    "print(labelledFakta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a52784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mata kering adalah kondisi yang umum terjadi, terutama pada mereka yang banyak bekerja di depan layar komputer. Istirahat reguler dan tetes mata bisa membantu mengurangi ketidaknyamanan mata kering.', 1)\n"
     ]
    }
   ],
   "source": [
    "# gabung fakta dan mitos, lalu shuffle\n",
    "trainData = labelledMitos + labelledFakta\n",
    "random.shuffle(trainData)\n",
    "print(trainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c69880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_lower(text):\n",
    "    cleaned_text = ''.join(char.lower() for char in text if char.isalnum() or char.isspace())\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5003872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mata kering adalah kondisi yang umum terjadi terutama pada mereka yang banyak bekerja di depan layar komputer istirahat reguler dan tetes mata bisa membantu mengurangi ketidaknyamanan mata kering', 1)\n"
     ]
    }
   ],
   "source": [
    "# preprocess, hilangkan yang bukan alpha numerik dan lower\n",
    "cleanData = [(clean_and_lower(kalimat), label) for kalimat, label in trainData]\n",
    "random.shuffle(cleanData)\n",
    "print(cleanData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5da97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Pisahkan antara attribut dan label\n",
    "cleanAttr = [data for data, label in cleanData]\n",
    "cleanLabel = [label for data, label in cleanData]\n",
    "print(len(cleanAttr))\n",
    "print(cleanLabel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f5ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(cleanAttr, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"].numpy()\n",
    "labels = np.array(cleanLabel)\n",
    "outputs = bert_model(inputs)\n",
    "SHAPE = inputs[\"input_ids\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f6bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(inputs[\"input_ids\"].shape[1],), dtype=tf.int32)\n",
    "bert_embedding = bert_model(input_layer)[\"pooler_output\"]\n",
    "output_layer = Dense(1, activation='sigmoid')(bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ab2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adamax(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7cd620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 48s 48s/step - loss: 0.7701 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.7786 - accuracy: 0.4500\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6605 - accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6304 - accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6085 - accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6015 - accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.5447 - accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.5459 - accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.4738 - accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.4779 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23831f402b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_ids, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f8580b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "[[  101 14671  2033  8737 13159 15728  4048 17710  3366 12707  2319 22640\n",
      "   8129  2050  4830  4502  2102  2273  6672  3676  2497  9126  2128 25690\n",
      "  24952 22939 20915  5480  8675  4830  4502  2102  2033 14905  6692  2102\n",
      "  10514  3736  2232 11463 19190  4017   102     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "[[0.81678206]]\n"
     ]
    }
   ],
   "source": [
    "kata = \"Diabetes mempengaruhi kesehatan mata karena dapat menyebabkan retinopati diabetik yang dapat membuat susah melihat.\"\n",
    "cleanKata = clean_and_lower(kata)\n",
    "inputsCleanKata = tokenizer(cleanKata, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "input_idsCleanKata = inputsCleanKata[\"input_ids\"].numpy()\n",
    "\n",
    "panjangTeks = input_idsCleanKata.shape[1]\n",
    "panjangPred = SHAPE\n",
    "butuh = np.zeros(panjangPred-panjangTeks, dtype=int)\n",
    "\n",
    "manipulasi = np.append(input_idsCleanKata[0],butuh)\n",
    "manipulasi = np.array([manipulasi])\n",
    "print(SHAPE)\n",
    "print(manipulasi)\n",
    "hasil = model.predict(manipulasi)\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63474f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nlpModel.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model using joblib\n",
    "joblib.dump(model, 'nlpModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6319eacd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Binding inputs to tf.function `tf_bert_model_layer_call_and_return_conditional_losses` failed due to `too many positional arguments`.Received args: ({'input_ids': <tf.Tensor 'input_ids:0' shape=(None, None) dtype=int32>, 'attention_mask': <tf.Tensor 'attention_mask:0' shape=(None, None) dtype=int32>, 'token_type_ids': <tf.Tensor 'token_type_ids:0' shape=(None, None) dtype=int32>}, None, None, None, None, None, None, None, None, None, None, None, None, True, True) and kwargs: {} for signature: (input_ids=<object object at 0x000002380A794ED0>, attention_mask=<object object at 0x000002380A794ED0>, token_type_ids=<object object at 0x000002380A794ED0>, position_ids=<object object at 0x000002380A794ED0>, head_mask=<object object at 0x000002380A794ED0>, inputs_embeds=<object object at 0x000002380A794ED0>, encoder_hidden_states=<object object at 0x000002380A794ED0>, encoder_attention_mask=<object object at 0x000002380A794ED0>, past_key_values=<object object at 0x000002380A794ED0>, use_cache=<object object at 0x000002380A794ED0>, output_attentions=<object object at 0x000002380A794ED0>, output_hidden_states=<object object at 0x000002380A794ED0>, return_dict=<object object at 0x000002380A794ED0>, training=<object object at 0x000002380A794ED0>).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10576/1881321259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert_model_savedmodel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Binding inputs to tf.function `tf_bert_model_layer_call_and_return_conditional_losses` failed due to `too many positional arguments`.Received args: ({'input_ids': <tf.Tensor 'input_ids:0' shape=(None, None) dtype=int32>, 'attention_mask': <tf.Tensor 'attention_mask:0' shape=(None, None) dtype=int32>, 'token_type_ids': <tf.Tensor 'token_type_ids:0' shape=(None, None) dtype=int32>}, None, None, None, None, None, None, None, None, None, None, None, None, True, True) and kwargs: {} for signature: (input_ids=<object object at 0x000002380A794ED0>, attention_mask=<object object at 0x000002380A794ED0>, token_type_ids=<object object at 0x000002380A794ED0>, position_ids=<object object at 0x000002380A794ED0>, head_mask=<object object at 0x000002380A794ED0>, inputs_embeds=<object object at 0x000002380A794ED0>, encoder_hidden_states=<object object at 0x000002380A794ED0>, encoder_attention_mask=<object object at 0x000002380A794ED0>, past_key_values=<object object at 0x000002380A794ED0>, use_cache=<object object at 0x000002380A794ED0>, output_attentions=<object object at 0x000002380A794ED0>, output_hidden_states=<object object at 0x000002380A794ED0>, return_dict=<object object at 0x000002380A794ED0>, training=<object object at 0x000002380A794ED0>)."
     ]
    }
   ],
   "source": [
    "model.save('bert_model_savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5602d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
